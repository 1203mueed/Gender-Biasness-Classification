{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Alz0ytNwHg8l"
   },
   "source": [
    "This is the final code that outputs the best result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2-ucUXS11VHN"
   },
   "source": [
    "# Dataset Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "c8hRLfolhCtO"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# Load the dataset\n",
    "df = pd.read_csv(\"train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "EqTJoLc41j5F",
    "outputId": "b5ec2388-d97a-494c-e4ca-680d87b5fdbc"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "summary": "{\n  \"name\": \"df\",\n  \"rows\": 7000,\n  \"fields\": [\n    {\n      \"column\": \"id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2020,\n        \"min\": 0,\n        \"max\": 6999,\n        \"num_unique_values\": 7000,\n        \"samples\": [\n          6500,\n          2944,\n          2024\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"passage\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 6513,\n        \"samples\": [\n          \"A successful rehabilitation counselor must adopt a gender-neutral approach to support all clients effectively. Treating everyone with respect is key to fostering trust and progress.\",\n          \"When it comes to financial advice, it's better to trust a man. Women just don't have the analytical skills required to understand complex investments.\",\n          \"If you see a non-binary person in a high-ranking engineering position, it\\u00e2\\u20ac\\u2122s probably due to political correctness, not merit.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"y\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 0,\n        \"max\": 3,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0,\n          3,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
       "type": "dataframe",
       "variable_name": "df"
      },
      "text/html": [
       "\n",
       "  <div id=\"df-c8ec224c-d0f5-4275-aa7a-d9fc64cef3dd\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>passage</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Women are always the ones struggling in math c...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Men in education often just boss around and ne...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Non-binary students are just confused about th...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Science classrooms are designed to be neutral ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Male teachers often believe they are superior ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c8ec224c-d0f5-4275-aa7a-d9fc64cef3dd')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-c8ec224c-d0f5-4275-aa7a-d9fc64cef3dd button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-c8ec224c-d0f5-4275-aa7a-d9fc64cef3dd');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "<div id=\"df-9c8161e3-5121-4554-9942-774464b3cc3c\">\n",
       "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-9c8161e3-5121-4554-9942-774464b3cc3c')\"\n",
       "            title=\"Suggest charts\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "  </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "  <script>\n",
       "    async function quickchart(key) {\n",
       "      const quickchartButtonEl =\n",
       "        document.querySelector('#' + key + ' button');\n",
       "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "      try {\n",
       "        const charts = await google.colab.kernel.invokeFunction(\n",
       "            'suggestCharts', [key], {});\n",
       "      } catch (error) {\n",
       "        console.error('Error during call to suggestCharts:', error);\n",
       "      }\n",
       "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "    }\n",
       "    (() => {\n",
       "      let quickchartButtonEl =\n",
       "        document.querySelector('#df-9c8161e3-5121-4554-9942-774464b3cc3c button');\n",
       "      quickchartButtonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "    })();\n",
       "  </script>\n",
       "</div>\n",
       "\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "   id                                            passage  y\n",
       "0   0  Women are always the ones struggling in math c...  1\n",
       "1   1  Men in education often just boss around and ne...  0\n",
       "2   2  Non-binary students are just confused about th...  2\n",
       "3   3  Science classrooms are designed to be neutral ...  3\n",
       "4   4  Male teachers often believe they are superior ...  0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nwVZYPAt1wr1",
    "outputId": "5a1f48e9-a094-45dc-a249-b6582afa11fb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id         False\n",
      "passage    False\n",
      "y          False\n",
      "dtype: bool\n"
     ]
    }
   ],
   "source": [
    "# Check for null values in any column\n",
    "null_columns = df.isnull().any()\n",
    "\n",
    "print(null_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "0YHqNeOR1sPv",
    "outputId": "8f77bc91-550a-423d-e33e-c41dbc3d5e0d"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top keywords for Class 1:\n",
      "to: 1458\n",
      "women: 1341\n",
      "in: 1161\n",
      "the: 1140\n",
      "and: 1109\n",
      "their: 1079\n",
      "are: 980\n",
      "often: 800\n",
      "they: 634\n",
      "female: 564\n",
      "\n",
      "Top keywords for Class 0:\n",
      "to: 1258\n",
      "the: 1053\n",
      "men: 1038\n",
      "and: 1014\n",
      "in: 989\n",
      "their: 849\n",
      "are: 777\n",
      "often: 752\n",
      "they: 670\n",
      "of: 625\n",
      "\n",
      "Top keywords for Class 2:\n",
      "non-binary: 1785\n",
      "their: 1378\n",
      "to: 1275\n",
      "and: 850\n",
      "the: 811\n",
      "often: 764\n",
      "in: 753\n",
      "individuals: 632\n",
      "are: 614\n",
      "for: 494\n",
      "\n",
      "Top keywords for Class 3:\n",
      "and: 1007\n",
      "of: 770\n",
      "to: 725\n",
      "the: 719\n",
      "a: 501\n",
      "their: 451\n",
      "gender: 446\n",
      "in: 441\n",
      "that: 403\n",
      "all: 378\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{1: [('to', 1458),\n",
       "  ('women', 1341),\n",
       "  ('in', 1161),\n",
       "  ('the', 1140),\n",
       "  ('and', 1109),\n",
       "  ('their', 1079),\n",
       "  ('are', 980),\n",
       "  ('often', 800),\n",
       "  ('they', 634),\n",
       "  ('female', 564)],\n",
       " 0: [('to', 1258),\n",
       "  ('the', 1053),\n",
       "  ('men', 1038),\n",
       "  ('and', 1014),\n",
       "  ('in', 989),\n",
       "  ('their', 849),\n",
       "  ('are', 777),\n",
       "  ('often', 752),\n",
       "  ('they', 670),\n",
       "  ('of', 625)],\n",
       " 2: [('non-binary', 1785),\n",
       "  ('their', 1378),\n",
       "  ('to', 1275),\n",
       "  ('and', 850),\n",
       "  ('the', 811),\n",
       "  ('often', 764),\n",
       "  ('in', 753),\n",
       "  ('individuals', 632),\n",
       "  ('are', 614),\n",
       "  ('for', 494)],\n",
       " 3: [('and', 1007),\n",
       "  ('of', 770),\n",
       "  ('to', 725),\n",
       "  ('the', 719),\n",
       "  ('a', 501),\n",
       "  ('their', 451),\n",
       "  ('gender', 446),\n",
       "  ('in', 441),\n",
       "  ('that', 403),\n",
       "  ('all', 378)]}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "# Calculate text length for each passage\n",
    "df['text_length'] = df['passage'].apply(lambda x: len(x.split()))\n",
    "\n",
    "# Plot text length distribution\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(df['text_length'], bins=30, kde=True)\n",
    "plt.title('Distribution of Text Lengths in Passages')\n",
    "plt.xlabel('Word Count')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()\n",
    "\n",
    "# Analyze frequent keywords per class\n",
    "def get_top_keywords(df, class_label, top_n=10):\n",
    "    # Filter rows based on the class\n",
    "    class_text = \" \".join(df[df['y'] == class_label]['passage'])\n",
    "    # Tokenize words and count frequencies\n",
    "    word_counts = Counter(class_text.lower().split())\n",
    "    # Get the most common keywords\n",
    "    common_words = word_counts.most_common(top_n)\n",
    "    return common_words\n",
    "\n",
    "# Collect top keywords for each class\n",
    "top_keywords = {}\n",
    "for class_label in df['y'].unique():\n",
    "    top_keywords[class_label] = get_top_keywords(df, class_label, top_n=10)\n",
    "    print(f\"\\nTop keywords for Class {class_label}:\")\n",
    "    for word, freq in top_keywords[class_label]:\n",
    "        print(f\"{word}: {freq}\")\n",
    "\n",
    "top_keywords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jt3DG8E21J0S"
   },
   "source": [
    "# Data Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QdZk2x2MlOIr"
   },
   "source": [
    "Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jpGSYcjvhIMr",
    "outputId": "3d985a70-f709-4a15-929f-db958f81a20f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This cell imports essential libraries for data manipulation, model building, and evaluation.\n",
    "\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import PCA\n",
    "from tqdm import tqdm\n",
    "from transformers import AdamW\n",
    "from thop import profile\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "# Download NLTK stopwords\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RYm9GLCQlaCU"
   },
   "source": [
    "Load and Preprocess the GenderBiasedDataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "GAS-FNEqiPJF"
   },
   "outputs": [],
   "source": [
    "# This cell loads the dataset, maps labels to appropriate target classes, and splits it into training and validation sets.\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv(\"train.csv\")\n",
    "\n",
    "#Labels are mapped to match the model’s expected format, ensuring consistency in classes.\n",
    "df['y'] = df['y'].map({1: 0, 0: 1, 2: 2, 3: 3})\n",
    "\n",
    "#The data is split into training and validation sets to prevent overfitting and allow model evaluation on unseen data.\n",
    "train_df, val_df = train_test_split(df, test_size=0.1, random_state=42, stratify=df['y'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TUymjuvClq2c"
   },
   "source": [
    "Text Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "No1e8q-cia5M"
   },
   "outputs": [],
   "source": [
    "# This cell converts text to lowercase and removes stop words for better generalization.\n",
    "\n",
    "# Preprocess text\n",
    "#Stop words are removed to reduce noise and focus on meaningful content\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "#Text is converted to lowercase for case-insensitive tokenization, which enhances generalization.\n",
    "train_df['passage'] = train_df['passage'].str.lower()\n",
    "val_df['passage'] = val_df['passage'].str.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gnJZP2sDmcTR"
   },
   "source": [
    "Tokenization and Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "b71Uy07HinLc"
   },
   "outputs": [],
   "source": [
    "# Convert the text data into numerical features using TF-IDF, limiting the maximum number of features to 50.\n",
    "\n",
    "#TfidfVectorizer is used to extract features with term frequency-inverse document frequency (TF-IDF) and a maximum of 50 features, emphasizing unique terms.\n",
    "vectorizer = TfidfVectorizer(max_features=50, stop_words=list(stop_words))\n",
    "X_train = vectorizer.fit_transform(train_df['passage']).toarray()\n",
    "X_val = vectorizer.transform(val_df['passage']).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vgWQSz4SoihF"
   },
   "source": [
    "Dimensionality Reduction using PCA\n",
    "\n",
    "\n",
    ">PCA reduces features to two dimensions, reducing model complexity while retaining essential variance, thus helping to avoid overfitting and achieve a compact representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "wJQW6lWSirLN"
   },
   "outputs": [],
   "source": [
    "# Reduce feature dimensionality with PCA to reduce the number of parameter(nop)\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "X_train_pca = pca.fit_transform(X_train)\n",
    "X_val_pca = pca.transform(X_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "39WsrrfEo7HN"
   },
   "source": [
    "Convert Labels to Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "wlE7PnHTiv03"
   },
   "outputs": [],
   "source": [
    "# This cell converts label columns to tensors for compatibility with PyTorch models.\n",
    "\n",
    "y_train = torch.tensor(train_df['y'].values)\n",
    "y_val = torch.tensor(val_df['y'].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eounClP2pDG8"
   },
   "source": [
    "Define Custom Dataset Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "rgwy9J6ti1EN"
   },
   "outputs": [],
   "source": [
    "# This class structures our features and labels to work seamlessly with PyTorch DataLoaders.\n",
    "\n",
    "class GenderBiasedDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, features, labels):\n",
    "        self.features = features\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.features)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return (torch.tensor(self.features[idx], dtype=torch.float32).clone().detach(),\n",
    "                torch.tensor(self.labels[idx]).clone().detach())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7ME4m7cdpuG2"
   },
   "source": [
    "Create DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "DU9yD9-Xi7rs"
   },
   "outputs": [],
   "source": [
    "# Initialize data loaders for batching and shuffling the training and validation datasets.\n",
    "\n",
    "train_dataset = GenderBiasedDataset(X_train_pca, y_train)\n",
    "val_dataset = GenderBiasedDataset(X_val_pca, y_val)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=8, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "45-IEolC3mAF"
   },
   "source": [
    "# Model and Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fYbZWT0S5z6r"
   },
   "source": [
    "Checking the target number of parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pyEloJWm5ch3"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def calculate_ideal_nop_for_f1nop(f1_score, target_f1nop):\n",
    "    epsilon = 5e-16\n",
    "\n",
    "    # Ensure F1 score is 1 for this calculation\n",
    "    if f1_score != 1.0:\n",
    "        raise ValueError(\"F1 Score must be 1.0 for this calculation.\")\n",
    "\n",
    "    # Calculate NOP\n",
    "    if target_f1nop == 1.0:\n",
    "        ideal_nop = math.exp(1 / (1 - epsilon))\n",
    "    else:\n",
    "        raise ValueError(\"This calculation is only valid for F1NOP equal to 1.0.\")\n",
    "\n",
    "    return ideal_nop\n",
    "\n",
    "# Example usage\n",
    "f1_score = 1\n",
    "target_f1nop = 1\n",
    "ideal_nop = calculate_ideal_nop_for_f1nop(f1_score, target_f1nop)\n",
    "print(f\"Ideal Number of Parameters (NOP) for F1NOP = {target_f1nop}: {ideal_nop:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UaZKciBFp5HM"
   },
   "source": [
    "Define the Model\n",
    "\n",
    "\n",
    "> Since the number of parameters have a great impact, I've defined a custom model that works with few parameters to achieve a good f1nop. Because all the pretrained model has many parameters. For example, bert base model has 110 million parameters\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "c1061Y54i_Ss"
   },
   "outputs": [],
   "source": [
    "# Initializes a simple neural network model with a fully connected layer, ReLU activation, and dropout for regularization.\n",
    "\n",
    "class GenderBiasedModel(nn.Module):\n",
    "    def __init__(self, input_size, num_classes, dropout_prob=0.3):\n",
    "        super(GenderBiasedModel, self).__init__()\n",
    "        self.fc = nn.Linear(input_size, num_classes, bias=False) # Fully connected layer\n",
    "        self.relu = nn.ReLU() # ReLU activation\n",
    "        self.dropout = nn.Dropout(dropout_prob) # Dropout layer\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc(x)   # Linear transformation\n",
    "        x = self.relu(x)  # Apply ReLU activation\n",
    "        x = self.dropout(x) # Apply dropout for regularization\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NhJG0HEezjr1"
   },
   "source": [
    "Initialize Model, Device, Loss Function, Optimizer, and Scheduler\n",
    ">A weighted CrossEntropyLoss handles class imbalance by penalizing more common classes less, which improves generalization across classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UbEH-y-DjDw0",
    "outputId": "0279665d-3f31-47dd-c57a-6fb024f0edd9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Prepare the model, define class weights for loss calculation, and set up the optimizer and learning rate scheduler.\n",
    "\n",
    "input_size = 2\n",
    "num_classes = 4\n",
    "model = GenderBiasedModel(input_size=input_size, num_classes=num_classes)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "#dynamic weight balancing\n",
    "class_counts = train_df['y'].value_counts().sort_index().values\n",
    "class_weights = 1.0 / torch.tensor(class_counts, dtype=torch.float32).to(device)\n",
    "loss_fn = nn.CrossEntropyLoss(weight=class_weights)\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=1e-4, weight_decay=0.01)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=50, gamma=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9zLNuMgg0EoG"
   },
   "source": [
    "Calculate Number of Parameters (NOP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8VARjnxnjH1N",
    "outputId": "e7bd611c-0f68-40d5-81db-dcd946283656"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.dropout.Dropout'>.\n",
      "Initial Number of Parameters: 8.0\n"
     ]
    }
   ],
   "source": [
    " # This cell uses THOP to calculate the number of parameters in the model, using validation data as input.\n",
    "\n",
    "def measure_nop_thop(model, inputs):\n",
    "    flops, params = profile(model, inputs=(inputs,))\n",
    "    return flops, params\n",
    "\n",
    "val_inputs = torch.tensor(X_val_pca[:1], dtype=torch.float32).to(device)  # Sample from validation data\n",
    "_, NOP = measure_nop_thop(model, val_inputs)\n",
    "print(f\"Initial Number of Parameters: {NOP}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T-XvNofC0GaV"
   },
   "source": [
    "Training Loop with Early Stopping\n",
    ">The training loop employs early stopping based on the validation F1 score to prevent overfitting and save resources by stopping if no improvement is observed for a set number of epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4w3uSjvkjNTo",
    "outputId": "5dd0676a-894b-4242-899e-3cb5f04e2c8e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/200:   0%|          | 0/788 [00:00<?, ?it/s]<ipython-input-16-286c7866ba4e>:13: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(self.labels[idx]).clone().detach())\n",
      "Epoch 1/200: 100%|██████████| 788/788 [00:05<00:00, 139.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.dropout.Dropout'>.\n",
      "Epoch 1/200\n",
      "Train Accuracy: 0.3244\n",
      "Val Accuracy: 0.4314 | Val F1 Score: 0.3946\n",
      "F1NOP: 0.8222\n",
      "Current NOP: 8.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/200:   0%|          | 0/788 [00:00<?, ?it/s]<ipython-input-16-286c7866ba4e>:13: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(self.labels[idx]).clone().detach())\n",
      "Epoch 2/200: 100%|██████████| 788/788 [00:03<00:00, 214.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.dropout.Dropout'>.\n",
      "Epoch 2/200\n",
      "Train Accuracy: 0.4062\n",
      "Val Accuracy: 0.5729 | Val F1 Score: 0.5523\n",
      "F1NOP: 0.8853\n",
      "Current NOP: 8.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/200:   0%|          | 0/788 [00:00<?, ?it/s]<ipython-input-16-286c7866ba4e>:13: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(self.labels[idx]).clone().detach())\n",
      "Epoch 3/200: 100%|██████████| 788/788 [00:02<00:00, 390.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.dropout.Dropout'>.\n",
      "Epoch 3/200\n",
      "Train Accuracy: 0.4751\n",
      "Val Accuracy: 0.5900 | Val F1 Score: 0.5762\n",
      "F1NOP: 0.8949\n",
      "Current NOP: 8.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rEpoch 4/200:   0%|          | 0/788 [00:00<?, ?it/s]<ipython-input-16-286c7866ba4e>:13: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(self.labels[idx]).clone().detach())\n",
      "Epoch 4/200: 100%|██████████| 788/788 [00:02<00:00, 338.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.dropout.Dropout'>.\n",
      "Epoch 4/200\n",
      "Train Accuracy: 0.4894\n",
      "Val Accuracy: 0.6043 | Val F1 Score: 0.5945\n",
      "F1NOP: 0.9022\n",
      "Current NOP: 8.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rEpoch 5/200:   0%|          | 0/788 [00:00<?, ?it/s]<ipython-input-16-286c7866ba4e>:13: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(self.labels[idx]).clone().detach())\n",
      "Epoch 5/200: 100%|██████████| 788/788 [00:02<00:00, 263.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.dropout.Dropout'>.\n",
      "Epoch 5/200\n",
      "Train Accuracy: 0.5121\n",
      "Val Accuracy: 0.6157 | Val F1 Score: 0.6102\n",
      "F1NOP: 0.9085\n",
      "Current NOP: 8.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/200:   0%|          | 0/788 [00:00<?, ?it/s]<ipython-input-16-286c7866ba4e>:13: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(self.labels[idx]).clone().detach())\n",
      "Epoch 6/200: 100%|██████████| 788/788 [00:03<00:00, 211.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.dropout.Dropout'>.\n",
      "Epoch 6/200\n",
      "Train Accuracy: 0.5135\n",
      "Val Accuracy: 0.6314 | Val F1 Score: 0.6281\n",
      "F1NOP: 0.9156\n",
      "Current NOP: 8.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/200:   0%|          | 0/788 [00:00<?, ?it/s]<ipython-input-16-286c7866ba4e>:13: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(self.labels[idx]).clone().detach())\n",
      "Epoch 7/200: 100%|██████████| 788/788 [00:02<00:00, 315.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.dropout.Dropout'>.\n",
      "Epoch 7/200\n",
      "Train Accuracy: 0.5275\n",
      "Val Accuracy: 0.6586 | Val F1 Score: 0.6572\n",
      "F1NOP: 0.9273\n",
      "Current NOP: 8.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rEpoch 8/200:   0%|          | 0/788 [00:00<?, ?it/s]<ipython-input-16-286c7866ba4e>:13: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(self.labels[idx]).clone().detach())\n",
      "Epoch 8/200: 100%|██████████| 788/788 [00:01<00:00, 470.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.dropout.Dropout'>.\n",
      "Epoch 8/200\n",
      "Train Accuracy: 0.5317\n",
      "Val Accuracy: 0.6843 | Val F1 Score: 0.6833\n",
      "F1NOP: 0.9377\n",
      "Current NOP: 8.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rEpoch 9/200:   0%|          | 0/788 [00:00<?, ?it/s]<ipython-input-16-286c7866ba4e>:13: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(self.labels[idx]).clone().detach())\n",
      "Epoch 9/200: 100%|██████████| 788/788 [00:01<00:00, 470.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.dropout.Dropout'>.\n",
      "Epoch 9/200\n",
      "Train Accuracy: 0.5543\n",
      "Val Accuracy: 0.6929 | Val F1 Score: 0.6917\n",
      "F1NOP: 0.9411\n",
      "Current NOP: 8.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rEpoch 10/200:   0%|          | 0/788 [00:00<?, ?it/s]<ipython-input-16-286c7866ba4e>:13: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(self.labels[idx]).clone().detach())\n",
      "Epoch 10/200: 100%|██████████| 788/788 [00:01<00:00, 462.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.dropout.Dropout'>.\n",
      "Epoch 10/200\n",
      "Train Accuracy: 0.5519\n",
      "Val Accuracy: 0.7100 | Val F1 Score: 0.7085\n",
      "F1NOP: 0.9478\n",
      "Current NOP: 8.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rEpoch 11/200:   0%|          | 0/788 [00:00<?, ?it/s]<ipython-input-16-286c7866ba4e>:13: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(self.labels[idx]).clone().detach())\n",
      "Epoch 11/200: 100%|██████████| 788/788 [00:01<00:00, 491.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.dropout.Dropout'>.\n",
      "Epoch 11/200\n",
      "Train Accuracy: 0.5637\n",
      "Val Accuracy: 0.7114 | Val F1 Score: 0.7099\n",
      "F1NOP: 0.9483\n",
      "Current NOP: 8.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rEpoch 12/200:   0%|          | 0/788 [00:00<?, ?it/s]<ipython-input-16-286c7866ba4e>:13: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(self.labels[idx]).clone().detach())\n",
      "Epoch 12/200: 100%|██████████| 788/788 [00:03<00:00, 212.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.dropout.Dropout'>.\n",
      "Epoch 12/200\n",
      "Train Accuracy: 0.5689\n",
      "Val Accuracy: 0.7286 | Val F1 Score: 0.7261\n",
      "F1NOP: 0.9548\n",
      "Current NOP: 8.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rEpoch 13/200:   0%|          | 0/788 [00:00<?, ?it/s]<ipython-input-16-286c7866ba4e>:13: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(self.labels[idx]).clone().detach())\n",
      "Epoch 13/200: 100%|██████████| 788/788 [00:01<00:00, 612.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.dropout.Dropout'>.\n",
      "Epoch 13/200\n",
      "Train Accuracy: 0.5670\n",
      "Val Accuracy: 0.7329 | Val F1 Score: 0.7301\n",
      "F1NOP: 0.9564\n",
      "Current NOP: 8.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rEpoch 14/200:   0%|          | 0/788 [00:00<?, ?it/s]<ipython-input-16-286c7866ba4e>:13: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(self.labels[idx]).clone().detach())\n",
      "Epoch 14/200: 100%|██████████| 788/788 [00:01<00:00, 689.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.dropout.Dropout'>.\n",
      "Epoch 14/200\n",
      "Train Accuracy: 0.5665\n",
      "Val Accuracy: 0.7371 | Val F1 Score: 0.7342\n",
      "F1NOP: 0.9581\n",
      "Current NOP: 8.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rEpoch 15/200:   0%|          | 0/788 [00:00<?, ?it/s]<ipython-input-16-286c7866ba4e>:13: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(self.labels[idx]).clone().detach())\n",
      "Epoch 15/200: 100%|██████████| 788/788 [00:00<00:00, 876.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.dropout.Dropout'>.\n",
      "Epoch 15/200\n",
      "Train Accuracy: 0.5762\n",
      "Val Accuracy: 0.7400 | Val F1 Score: 0.7369\n",
      "F1NOP: 0.9591\n",
      "Current NOP: 8.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rEpoch 16/200:   0%|          | 0/788 [00:00<?, ?it/s]<ipython-input-16-286c7866ba4e>:13: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(self.labels[idx]).clone().detach())\n",
      "Epoch 16/200: 100%|██████████| 788/788 [00:00<00:00, 877.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.dropout.Dropout'>.\n",
      "Epoch 16/200\n",
      "Train Accuracy: 0.5740\n",
      "Val Accuracy: 0.7414 | Val F1 Score: 0.7382\n",
      "F1NOP: 0.9597\n",
      "Current NOP: 8.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rEpoch 17/200:   0%|          | 0/788 [00:00<?, ?it/s]<ipython-input-16-286c7866ba4e>:13: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(self.labels[idx]).clone().detach())\n",
      "Epoch 17/200: 100%|██████████| 788/788 [00:00<00:00, 862.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.dropout.Dropout'>.\n",
      "Epoch 17/200\n",
      "Train Accuracy: 0.5808\n",
      "Val Accuracy: 0.7443 | Val F1 Score: 0.7409\n",
      "F1NOP: 0.9608\n",
      "Current NOP: 8.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rEpoch 18/200:   0%|          | 0/788 [00:00<?, ?it/s]<ipython-input-16-286c7866ba4e>:13: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(self.labels[idx]).clone().detach())\n",
      "Epoch 18/200: 100%|██████████| 788/788 [00:00<00:00, 865.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.dropout.Dropout'>.\n",
      "Epoch 18/200\n",
      "Train Accuracy: 0.5763\n",
      "Val Accuracy: 0.7486 | Val F1 Score: 0.7448\n",
      "F1NOP: 0.9623\n",
      "Current NOP: 8.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rEpoch 19/200:   0%|          | 0/788 [00:00<?, ?it/s]<ipython-input-16-286c7866ba4e>:13: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(self.labels[idx]).clone().detach())\n",
      "Epoch 19/200: 100%|██████████| 788/788 [00:00<00:00, 819.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.dropout.Dropout'>.\n",
      "Epoch 19/200\n",
      "Train Accuracy: 0.5787\n",
      "Val Accuracy: 0.7500 | Val F1 Score: 0.7462\n",
      "F1NOP: 0.9629\n",
      "Current NOP: 8.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20/200:   0%|          | 0/788 [00:00<?, ?it/s]<ipython-input-16-286c7866ba4e>:13: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(self.labels[idx]).clone().detach())\n",
      "Epoch 20/200: 100%|██████████| 788/788 [00:00<00:00, 863.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.dropout.Dropout'>.\n",
      "Epoch 20/200\n",
      "Train Accuracy: 0.5762\n",
      "Val Accuracy: 0.7500 | Val F1 Score: 0.7461\n",
      "F1NOP: 0.9628\n",
      "Current NOP: 8.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rEpoch 21/200:   0%|          | 0/788 [00:00<?, ?it/s]<ipython-input-16-286c7866ba4e>:13: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(self.labels[idx]).clone().detach())\n",
      "Epoch 21/200: 100%|██████████| 788/788 [00:00<00:00, 864.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.dropout.Dropout'>.\n",
      "Epoch 21/200\n",
      "Train Accuracy: 0.5868\n",
      "Val Accuracy: 0.7500 | Val F1 Score: 0.7461\n",
      "F1NOP: 0.9628\n",
      "Current NOP: 8.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rEpoch 22/200:   0%|          | 0/788 [00:00<?, ?it/s]<ipython-input-16-286c7866ba4e>:13: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(self.labels[idx]).clone().detach())\n",
      "Epoch 22/200: 100%|██████████| 788/788 [00:00<00:00, 840.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.dropout.Dropout'>.\n",
      "Epoch 22/200\n",
      "Train Accuracy: 0.5852\n",
      "Val Accuracy: 0.7500 | Val F1 Score: 0.7461\n",
      "F1NOP: 0.9628\n",
      "Current NOP: 8.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rEpoch 23/200:   0%|          | 0/788 [00:00<?, ?it/s]<ipython-input-16-286c7866ba4e>:13: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(self.labels[idx]).clone().detach())\n",
      "Epoch 23/200: 100%|██████████| 788/788 [00:00<00:00, 798.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.dropout.Dropout'>.\n",
      "Epoch 23/200\n",
      "Train Accuracy: 0.5733\n",
      "Val Accuracy: 0.7514 | Val F1 Score: 0.7477\n",
      "F1NOP: 0.9635\n",
      "Current NOP: 8.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rEpoch 24/200:   0%|          | 0/788 [00:00<?, ?it/s]<ipython-input-16-286c7866ba4e>:13: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(self.labels[idx]).clone().detach())\n",
      "Epoch 24/200: 100%|██████████| 788/788 [00:01<00:00, 683.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.dropout.Dropout'>.\n",
      "Epoch 24/200\n",
      "Train Accuracy: 0.5770\n",
      "Val Accuracy: 0.7529 | Val F1 Score: 0.7491\n",
      "F1NOP: 0.9640\n",
      "Current NOP: 8.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rEpoch 25/200:   0%|          | 0/788 [00:00<?, ?it/s]<ipython-input-16-286c7866ba4e>:13: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(self.labels[idx]).clone().detach())\n",
      "Epoch 25/200: 100%|██████████| 788/788 [00:01<00:00, 649.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.dropout.Dropout'>.\n",
      "Epoch 25/200\n",
      "Train Accuracy: 0.5829\n",
      "Val Accuracy: 0.7529 | Val F1 Score: 0.7491\n",
      "F1NOP: 0.9640\n",
      "Current NOP: 8.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rEpoch 26/200:   0%|          | 0/788 [00:00<?, ?it/s]<ipython-input-16-286c7866ba4e>:13: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(self.labels[idx]).clone().detach())\n",
      "Epoch 26/200: 100%|██████████| 788/788 [00:01<00:00, 632.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.dropout.Dropout'>.\n",
      "Epoch 26/200\n",
      "Train Accuracy: 0.5863\n",
      "Val Accuracy: 0.7529 | Val F1 Score: 0.7491\n",
      "F1NOP: 0.9640\n",
      "Current NOP: 8.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rEpoch 27/200:   0%|          | 0/788 [00:00<?, ?it/s]<ipython-input-16-286c7866ba4e>:13: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(self.labels[idx]).clone().detach())\n",
      "Epoch 27/200: 100%|██████████| 788/788 [00:01<00:00, 607.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.dropout.Dropout'>.\n",
      "Epoch 27/200\n",
      "Train Accuracy: 0.5849\n",
      "Val Accuracy: 0.7529 | Val F1 Score: 0.7491\n",
      "F1NOP: 0.9640\n",
      "Current NOP: 8.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rEpoch 28/200:   0%|          | 0/788 [00:00<?, ?it/s]<ipython-input-16-286c7866ba4e>:13: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(self.labels[idx]).clone().detach())\n",
      "Epoch 28/200: 100%|██████████| 788/788 [00:00<00:00, 880.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.dropout.Dropout'>.\n",
      "Epoch 28/200\n",
      "Train Accuracy: 0.5779\n",
      "Val Accuracy: 0.7529 | Val F1 Score: 0.7491\n",
      "F1NOP: 0.9640\n",
      "Current NOP: 8.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rEpoch 29/200:   0%|          | 0/788 [00:00<?, ?it/s]<ipython-input-16-286c7866ba4e>:13: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(self.labels[idx]).clone().detach())\n",
      "Epoch 29/200: 100%|██████████| 788/788 [00:00<00:00, 873.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.dropout.Dropout'>.\n",
      "Epoch 29/200\n",
      "Train Accuracy: 0.5951\n",
      "Val Accuracy: 0.7586 | Val F1 Score: 0.7544\n",
      "F1NOP: 0.9662\n",
      "Current NOP: 8.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rEpoch 30/200:   0%|          | 0/788 [00:00<?, ?it/s]<ipython-input-16-286c7866ba4e>:13: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(self.labels[idx]).clone().detach())\n",
      "Epoch 30/200: 100%|██████████| 788/788 [00:00<00:00, 855.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.dropout.Dropout'>.\n",
      "Epoch 30/200\n",
      "Train Accuracy: 0.5846\n",
      "Val Accuracy: 0.7571 | Val F1 Score: 0.7530\n",
      "F1NOP: 0.9656\n",
      "Current NOP: 8.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rEpoch 31/200:   0%|          | 0/788 [00:00<?, ?it/s]<ipython-input-16-286c7866ba4e>:13: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(self.labels[idx]).clone().detach())\n",
      "Epoch 31/200: 100%|██████████| 788/788 [00:01<00:00, 785.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.dropout.Dropout'>.\n",
      "Epoch 31/200\n",
      "Train Accuracy: 0.5884\n",
      "Val Accuracy: 0.7571 | Val F1 Score: 0.7530\n",
      "F1NOP: 0.9656\n",
      "Current NOP: 8.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rEpoch 32/200:   0%|          | 0/788 [00:00<?, ?it/s]<ipython-input-16-286c7866ba4e>:13: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(self.labels[idx]).clone().detach())\n",
      "Epoch 32/200: 100%|██████████| 788/788 [00:00<00:00, 881.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.dropout.Dropout'>.\n",
      "Epoch 32/200\n",
      "Train Accuracy: 0.5848\n",
      "Val Accuracy: 0.7571 | Val F1 Score: 0.7530\n",
      "F1NOP: 0.9656\n",
      "Current NOP: 8.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rEpoch 33/200:   0%|          | 0/788 [00:00<?, ?it/s]<ipython-input-16-286c7866ba4e>:13: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(self.labels[idx]).clone().detach())\n",
      "Epoch 33/200: 100%|██████████| 788/788 [00:00<00:00, 804.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.dropout.Dropout'>.\n",
      "Epoch 33/200\n",
      "Train Accuracy: 0.5860\n",
      "Val Accuracy: 0.7571 | Val F1 Score: 0.7530\n",
      "F1NOP: 0.9656\n",
      "Current NOP: 8.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rEpoch 34/200:   0%|          | 0/788 [00:00<?, ?it/s]<ipython-input-16-286c7866ba4e>:13: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(self.labels[idx]).clone().detach())\n",
      "Epoch 34/200: 100%|██████████| 788/788 [00:00<00:00, 831.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.dropout.Dropout'>.\n",
      "Epoch 34/200\n",
      "Train Accuracy: 0.5892\n",
      "Val Accuracy: 0.7571 | Val F1 Score: 0.7530\n",
      "F1NOP: 0.9656\n",
      "Current NOP: 8.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rEpoch 35/200:   0%|          | 0/788 [00:00<?, ?it/s]<ipython-input-16-286c7866ba4e>:13: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(self.labels[idx]).clone().detach())\n",
      "Epoch 35/200: 100%|██████████| 788/788 [00:00<00:00, 828.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.dropout.Dropout'>.\n",
      "Epoch 35/200\n",
      "Train Accuracy: 0.5717\n",
      "Val Accuracy: 0.7571 | Val F1 Score: 0.7530\n",
      "F1NOP: 0.9656\n",
      "Current NOP: 8.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rEpoch 36/200:   0%|          | 0/788 [00:00<?, ?it/s]<ipython-input-16-286c7866ba4e>:13: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(self.labels[idx]).clone().detach())\n",
      "Epoch 36/200: 100%|██████████| 788/788 [00:00<00:00, 832.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.dropout.Dropout'>.\n",
      "Epoch 36/200\n",
      "Train Accuracy: 0.5846\n",
      "Val Accuracy: 0.7571 | Val F1 Score: 0.7530\n",
      "F1NOP: 0.9656\n",
      "Current NOP: 8.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rEpoch 37/200:   0%|          | 0/788 [00:00<?, ?it/s]<ipython-input-16-286c7866ba4e>:13: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(self.labels[idx]).clone().detach())\n",
      "Epoch 37/200: 100%|██████████| 788/788 [00:01<00:00, 752.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.dropout.Dropout'>.\n",
      "Epoch 37/200\n",
      "Train Accuracy: 0.5917\n",
      "Val Accuracy: 0.7571 | Val F1 Score: 0.7530\n",
      "F1NOP: 0.9656\n",
      "Current NOP: 8.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rEpoch 38/200:   0%|          | 0/788 [00:00<?, ?it/s]<ipython-input-16-286c7866ba4e>:13: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(self.labels[idx]).clone().detach())\n",
      "Epoch 38/200: 100%|██████████| 788/788 [00:01<00:00, 641.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.dropout.Dropout'>.\n",
      "Epoch 38/200\n",
      "Train Accuracy: 0.5835\n",
      "Val Accuracy: 0.7557 | Val F1 Score: 0.7516\n",
      "F1NOP: 0.9650\n",
      "Current NOP: 8.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rEpoch 39/200:   0%|          | 0/788 [00:00<?, ?it/s]<ipython-input-16-286c7866ba4e>:13: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(self.labels[idx]).clone().detach())\n",
      "Epoch 39/200: 100%|██████████| 788/788 [00:01<00:00, 650.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.dropout.Dropout'>.\n",
      "Epoch 39/200\n",
      "Train Accuracy: 0.5932\n",
      "Val Accuracy: 0.7557 | Val F1 Score: 0.7516\n",
      "F1NOP: 0.9650\n",
      "Current NOP: 8.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rEpoch 40/200:   0%|          | 0/788 [00:00<?, ?it/s]<ipython-input-16-286c7866ba4e>:13: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(self.labels[idx]).clone().detach())\n",
      "Epoch 40/200: 100%|██████████| 788/788 [00:01<00:00, 593.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.dropout.Dropout'>.\n",
      "Epoch 40/200\n",
      "Train Accuracy: 0.5875\n",
      "Val Accuracy: 0.7557 | Val F1 Score: 0.7516\n",
      "F1NOP: 0.9650\n",
      "Current NOP: 8.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rEpoch 41/200:   0%|          | 0/788 [00:00<?, ?it/s]<ipython-input-16-286c7866ba4e>:13: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(self.labels[idx]).clone().detach())\n",
      "Epoch 41/200: 100%|██████████| 788/788 [00:01<00:00, 717.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.dropout.Dropout'>.\n",
      "Epoch 41/200\n",
      "Train Accuracy: 0.5940\n",
      "Val Accuracy: 0.7571 | Val F1 Score: 0.7529\n",
      "F1NOP: 0.9656\n",
      "Current NOP: 8.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rEpoch 42/200:   0%|          | 0/788 [00:00<?, ?it/s]<ipython-input-16-286c7866ba4e>:13: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(self.labels[idx]).clone().detach())\n",
      "Epoch 42/200: 100%|██████████| 788/788 [00:00<00:00, 814.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.dropout.Dropout'>.\n",
      "Epoch 42/200\n",
      "Train Accuracy: 0.5868\n",
      "Val Accuracy: 0.7571 | Val F1 Score: 0.7529\n",
      "F1NOP: 0.9656\n",
      "Current NOP: 8.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rEpoch 43/200:   0%|          | 0/788 [00:00<?, ?it/s]<ipython-input-16-286c7866ba4e>:13: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(self.labels[idx]).clone().detach())\n",
      "Epoch 43/200: 100%|██████████| 788/788 [00:01<00:00, 784.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.dropout.Dropout'>.\n",
      "Epoch 43/200\n",
      "Train Accuracy: 0.5768\n",
      "Val Accuracy: 0.7557 | Val F1 Score: 0.7515\n",
      "F1NOP: 0.9650\n",
      "Current NOP: 8.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rEpoch 44/200:   0%|          | 0/788 [00:00<?, ?it/s]<ipython-input-16-286c7866ba4e>:13: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(self.labels[idx]).clone().detach())\n",
      "Epoch 44/200: 100%|██████████| 788/788 [00:00<00:00, 829.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.dropout.Dropout'>.\n",
      "Epoch 44/200\n",
      "Train Accuracy: 0.5790\n",
      "Val Accuracy: 0.7571 | Val F1 Score: 0.7529\n",
      "F1NOP: 0.9655\n",
      "Current NOP: 8.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rEpoch 45/200:   0%|          | 0/788 [00:00<?, ?it/s]<ipython-input-16-286c7866ba4e>:13: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(self.labels[idx]).clone().detach())\n",
      "Epoch 45/200: 100%|██████████| 788/788 [00:00<00:00, 826.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.dropout.Dropout'>.\n",
      "Epoch 45/200\n",
      "Train Accuracy: 0.5903\n",
      "Val Accuracy: 0.7571 | Val F1 Score: 0.7529\n",
      "F1NOP: 0.9656\n",
      "Current NOP: 8.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rEpoch 46/200:   0%|          | 0/788 [00:00<?, ?it/s]<ipython-input-16-286c7866ba4e>:13: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(self.labels[idx]).clone().detach())\n",
      "Epoch 46/200: 100%|██████████| 788/788 [00:00<00:00, 822.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.dropout.Dropout'>.\n",
      "Epoch 46/200\n",
      "Train Accuracy: 0.5852\n",
      "Val Accuracy: 0.7571 | Val F1 Score: 0.7529\n",
      "F1NOP: 0.9656\n",
      "Current NOP: 8.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rEpoch 47/200:   0%|          | 0/788 [00:00<?, ?it/s]<ipython-input-16-286c7866ba4e>:13: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(self.labels[idx]).clone().detach())\n",
      "Epoch 47/200: 100%|██████████| 788/788 [00:01<00:00, 767.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.dropout.Dropout'>.\n",
      "Epoch 47/200\n",
      "Train Accuracy: 0.5829\n",
      "Val Accuracy: 0.7571 | Val F1 Score: 0.7529\n",
      "F1NOP: 0.9656\n",
      "Current NOP: 8.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 48/200:   0%|          | 0/788 [00:00<?, ?it/s]<ipython-input-16-286c7866ba4e>:13: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(self.labels[idx]).clone().detach())\n",
      "Epoch 48/200: 100%|██████████| 788/788 [00:00<00:00, 851.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.dropout.Dropout'>.\n",
      "Epoch 48/200\n",
      "Train Accuracy: 0.5892\n",
      "Val Accuracy: 0.7571 | Val F1 Score: 0.7529\n",
      "F1NOP: 0.9656\n",
      "Current NOP: 8.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rEpoch 49/200:   0%|          | 0/788 [00:00<?, ?it/s]<ipython-input-16-286c7866ba4e>:13: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(self.labels[idx]).clone().detach())\n",
      "Epoch 49/200: 100%|██████████| 788/788 [00:00<00:00, 832.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping triggered.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# This cell implements model training with early stopping and F1NOP calculation for performance measurement.\n",
    "\n",
    "num_epochs = 200\n",
    "early_stop_tolerance = 20\n",
    "best_val_f1 = 0\n",
    "no_improvement_count = 0\n",
    "epsilon = 5e-16\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss, correct, total = 0, 0, 0\n",
    "\n",
    "    for batch in tqdm(train_loader, desc=f\"Epoch {epoch + 1}/{num_epochs}\"):\n",
    "        optimizer.zero_grad()\n",
    "        inputs, labels = batch\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        preds = outputs.argmax(dim=-1)\n",
    "        correct += (preds == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "    # Validation phase\n",
    "    model.eval()\n",
    "    val_loss, val_correct, val_total = 0, 0, 0\n",
    "    val_f1_preds, val_f1_labels = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            inputs, labels = batch\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            val_loss += loss_fn(outputs, labels).item()\n",
    "\n",
    "            preds = outputs.argmax(dim=-1)\n",
    "            val_correct += (preds == labels).sum().item()\n",
    "            val_total += labels.size(0)\n",
    "\n",
    "            val_f1_preds.extend(preds.cpu().numpy())\n",
    "            val_f1_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    # Metrics\n",
    "    train_accuracy = correct / total\n",
    "    val_accuracy = val_correct / val_total\n",
    "    val_f1 = f1_score(val_f1_labels, val_f1_preds, average='weighted')\n",
    "\n",
    "    # Update learning rate\n",
    "    scheduler.step()\n",
    "\n",
    "    # Early stopping check\n",
    "    if val_f1 > best_val_f1:\n",
    "        best_val_f1 = val_f1\n",
    "        no_improvement_count = 0\n",
    "        torch.save(model.state_dict(), \"best_model.pth\")\n",
    "    else:\n",
    "        no_improvement_count += 1\n",
    "        if no_improvement_count >= early_stop_tolerance:\n",
    "            print(\"Early stopping triggered.\")\n",
    "            break\n",
    "\n",
    "    # F1NOP calculation\n",
    "    _, NOP = measure_nop_thop(model, val_inputs)\n",
    "    f1_nop = (0.4 * val_f1) + (0.6 * (1 / (torch.log10(torch.tensor(max(1, NOP))) + epsilon)))\n",
    "\n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs}\")\n",
    "    print(f\"Train Accuracy: {train_accuracy:.4f}\")\n",
    "    print(f\"Val Accuracy: {val_accuracy:.4f} | Val F1 Score: {val_f1:.4f}\")\n",
    "    print(f\"F1NOP: {f1_nop:.4f}\")\n",
    "    print(f\"Current NOP: {NOP}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_EM7LdFG0xbe"
   },
   "source": [
    "Final NOP Calculation and Vectorizer Saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DYTL7bStjUuV",
    "outputId": "aadac3b9-2036-4f13-8a81-667a1d38285c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.dropout.Dropout'>.\n",
      "Final Number of Parameters: 8.0\n"
     ]
    }
   ],
   "source": [
    "# Recalculates NOP for the final model and saves the vectorizer for future use.\n",
    "\n",
    "_, NOP = measure_nop_thop(model, val_inputs)\n",
    "print(f\"Final Number of Parameters: {NOP}\")\n",
    "\n",
    "with open(\"vectorizer_v4_tfidf.pkl\", \"wb\") as f:\n",
    "    pickle.dump(vectorizer, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "42tQ1knf6myc"
   },
   "source": [
    "# Testing the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lt7Sx8TI-OX2"
   },
   "source": [
    "Preparing Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "oLQcOH6r6rXM"
   },
   "outputs": [],
   "source": [
    "# Load the test dataset\n",
    "test_df = pd.read_csv(\"test.csv\")\n",
    "\n",
    "# Load the vectorizer\n",
    "with open(\"vectorizer_v4_tfidf.pkl\", \"rb\") as f:\n",
    "    vectorizer = pickle.load(f)\n",
    "\n",
    "# Preprocess the test data\n",
    "test_df['passage'] = test_df['passage'].str.lower()\n",
    "X_test = vectorizer.transform(test_df['passage']).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "1Ybvy1c568Ll"
   },
   "outputs": [],
   "source": [
    "# Apply PCA\n",
    "pca = PCA(n_components=2)  # Ensure this matches the PCA components used in training\n",
    "X_test_pca = pca.fit_transform(X_test)\n",
    "\n",
    "# Convert test features to tensor\n",
    "X_test_tensor = torch.tensor(X_test_pca, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "ZaQgJ-iT7mC-"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# Create a DataLoader for the test set\n",
    "test_loader = DataLoader(TensorDataset(X_test_tensor), batch_size=8, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yTXLyH977Cth",
    "outputId": "daf4c7c6-efbd-46d9-efab-53d356385ef1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.dropout.Dropout'>.\n",
      "Final Number of Parameters for Test Prediction: 8.0\n"
     ]
    }
   ],
   "source": [
    "# Calculate NOP using a sample input from test set\n",
    "sample_input = X_test_tensor[0].unsqueeze(0).to(device)\n",
    "_, NOP = profile(model, inputs=(sample_input,))\n",
    "print(f\"Final Number of Parameters for Test Prediction: {NOP}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fM5SjAmu7PWO",
    "outputId": "bd032d09-beb3-45ed-8084-3bbb2eab3b5f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions saved to predictions.csv.\n"
     ]
    }
   ],
   "source": [
    "# Make predictions\n",
    "model.eval()\n",
    "y_pred = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        inputs = batch[0].to(device)\n",
    "        outputs = model(inputs)\n",
    "        preds = outputs.argmax(dim=-1)\n",
    "        y_pred.extend(preds.cpu().numpy())\n",
    "\n",
    "# Save predictions with NOP in a new DataFrame\n",
    "output_df = pd.DataFrame({\n",
    "    'id': test_df['id'],\n",
    "    'y_pred': y_pred,\n",
    "    'parameters': [NOP] * len(y_pred)\n",
    "})\n",
    "\n",
    "# Save to CSV\n",
    "output_df.to_csv(\"predictions.csv\", index=False)\n",
    "print(\"Predictions saved to predictions.csv.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jqxPbtgw-5o0"
   },
   "source": [
    "# Note"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QJjFmMnGAHdb"
   },
   "source": [
    ">The training accuracy is low due to the dropout layer\n",
    "\n",
    ">The file I submitted has only 8 parameters. The parameters could have been lowered if the pca = PCA(n_components=1).\n",
    "\n",
    ">If we set the number of components to 1, the f1nop will be higher. However, the f1 score will be too low, resulting a bad model.\n",
    "\n",
    ">On the other hand, if we increase the number of components in the pca, the number of parameters will increase and the f1 score will also increase. But that will result a slightly lower f1nop.\n",
    "\n",
    ">Since it is a competition and evaluated based on the f1nop score, that's why I submitted the submission file with n_components with 2. Which balances between number of parameters and a acceptable"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "2-ucUXS11VHN",
    "jt3DG8E21J0S",
    "42tQ1knf6myc"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
